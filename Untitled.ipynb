{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from subprocess import check_output\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "#from sklearn.cross_validation import  train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# to not display the warnings of tensorflow\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_number(s):\n",
    "    return float(s.replace(',', '.'))\n",
    "\n",
    "def date_corrector(s):\n",
    "    return str(s[0:6]+'20'+s[6:8])\n",
    "\n",
    "def format_dataset(stock):\n",
    "    df = pd.read_csv(stock,delimiter=';')\n",
    "    df = df.rename(index=str, columns={df.columns[0]:\"name\",df.columns[1]:\"date\",df.columns[2]:\"open\",df.columns[3]:\"high\",df.columns[4]:\"low\",df.columns[5]:\"close\",df.columns[6]:\"volume\"})\n",
    "    df.open = list(map(format_number, df.open))\n",
    "    df.high = list(map(format_number, df.high))\n",
    "    df.low = list(map(format_number, df.low))\n",
    "    df.close = list(map(format_number, df.close))\n",
    "    df.date = list(map(date_corrector,df.date))\n",
    "    return df\n",
    "\n",
    "def get_movement(df):\n",
    "    i = 1\n",
    "    close_value = df.fft_100_close.values.tolist()\n",
    "    pct_close_mvt = [0]\n",
    "    while i < len(close_value):\n",
    "        pct_close_mvt.append((fft_100_close[i]-fft_100_close[i-1])/fft_100_close[i-1]*100.0)\n",
    "        i += 1\n",
    "    return pct_close_mvt\n",
    "    \n",
    "def get_technical_indicators(df):\n",
    "    # Create 7 and 21 days Moving Average\n",
    "    df['ma20'] = df['fft_100_close'].rolling(window=20).mean()\n",
    "    df['ma50'] = df['fft_100_close'].rolling(window=50).mean()\n",
    "    df['ma150'] = df['fft_100_close'].rolling(window=150).mean()\n",
    "    df['amd20'] = df['fft_100_close'].ewm(span=20,adjust=False).mean()\n",
    "    df['amd50'] = df['fft_100_close'].ewm(span=50,adjust=False).mean()\n",
    "    df['var_mma'] = (df['ma50']-df['ma20'])\n",
    "    df['var_amd'] = (df['amd50']-df['amd20'])\n",
    "    # Create MACD\n",
    "    df['26ema'] = pd.ewma(df['fft_100_close'], span=26)\n",
    "    df['12ema'] = pd.ewma(df['fft_100_close'], span=12)\n",
    "    df['MACD'] = (df['12ema']-df['26ema'])\n",
    "    df['signal'] = pd.ewma(df['MACD'], span=9)\n",
    "    df['var_macd'] = (df['MACD']-df['signal'])\n",
    "    # Create Bollinger Bands\n",
    "    df['20sd'] = pd.stats.moments.rolling_std(df['fft_100_close'],20)\n",
    "    df['ma21'] = df['fft_100_close'].rolling(window=21).mean()\n",
    "    df['upper_band'] = df['ma21'] + (df['20sd']*2)\n",
    "    df['lower_band'] = df['ma21'] - (df['20sd']*2)\n",
    "    df['var_bollinger'] = df['upper_band']- df['lower_band']\n",
    "    # Create Exponential moving average\n",
    "    df['ema'] = df['MACD'].ewm(com=0.5).mean()\n",
    "    return df\n",
    "\n",
    "def fourier_transform_close(df,fft_3_close,fft_6_close,fft_10_close,fft_100_close):\n",
    "    data_FT = df[['date', 'close']]\n",
    "    close_fft = np.fft.fft(np.asarray(data_FT['close'].tolist()))\n",
    "    fft_df = pd.DataFrame({'fft':close_fft})\n",
    "    fft_df['absolute'] = fft_df['fft'].apply(lambda x: np.abs(x))\n",
    "    fft_df['angle'] = fft_df['fft'].apply(lambda x: np.angle(x))\n",
    "    plt.figure(figsize=(14, 7), dpi=100)\n",
    "    fft_list = np.asarray(fft_df['fft'].tolist())\n",
    "    for num_ in [3,6,10,100]:\n",
    "        fft_list_m10=np.copy(fft_list); fft_list_m10[num_:-num_]=0\n",
    "        if num_ == 3:\n",
    "            fft_3_close.append(list(np.fft.ifft(fft_list_m10).real.tolist()))\n",
    "        if num_ == 6:\n",
    "            fft_6_close.append(list(np.fft.ifft(fft_list_m10).real.tolist()))\n",
    "        if num_ == 10:\n",
    "            fft_10_close.append(list(np.fft.ifft(fft_list_m10).real.tolist()))\n",
    "        if num_ == 100:\n",
    "            fft_100_close.append(list(np.fft.ifft(fft_list_m10).real.tolist()))\n",
    "    return(fft_df)\n",
    "\n",
    "def fourier_transform_low(df,fft_3_low,fft_6_low,fft_10_low,fft_100_low):\n",
    "    data_FT = df[['date', 'low']]\n",
    "    low_fft = np.fft.fft(np.asarray(data_FT['low'].tolist()))\n",
    "    fft_df = pd.DataFrame({'fft':low_fft})\n",
    "    fft_df['absolute'] = fft_df['fft'].apply(lambda x: np.abs(x))\n",
    "    fft_df['angle'] = fft_df['fft'].apply(lambda x: np.angle(x))\n",
    "    plt.figure(figsize=(14, 7), dpi=100)\n",
    "    fft_list = np.asarray(fft_df['fft'].tolist())\n",
    "    for num_ in [3,6,10,100]:\n",
    "        fft_list_m10=np.copy(fft_list); fft_list_m10[num_:-num_]=0\n",
    "        if num_ == 3:\n",
    "            fft_3_low.append(list(np.fft.ifft(fft_list_m10).real.tolist()))\n",
    "        if num_ == 6:\n",
    "            fft_6_low.append(list(np.fft.ifft(fft_list_m10).real.tolist()))\n",
    "        if num_ == 10:\n",
    "            fft_10_low.append(list(np.fft.ifft(fft_list_m10).real.tolist()))\n",
    "        fft_list_m10=np.copy(fft_list); fft_list_m10[num_:-num_]=0\n",
    "        if num_ == 100:\n",
    "            fft_100_low.append(list(np.fft.ifft(fft_list_m10).real.tolist()))\n",
    "    return(fft_df)\n",
    "\n",
    "def fourier_transform_high(df,fft_3_high,fft_6_high,fft_10_high,fft_100_high):\n",
    "    data_FT = df[['date', 'high']]\n",
    "    high_fft = np.fft.fft(np.asarray(data_FT['high'].tolist()))\n",
    "    fft_df = pd.DataFrame({'fft':high_fft})\n",
    "    fft_df['absolute'] = fft_df['fft'].apply(lambda x: np.abs(x))\n",
    "    fft_df['angle'] = fft_df['fft'].apply(lambda x: np.angle(x))\n",
    "    plt.figure(figsize=(14, 7), dpi=100)\n",
    "    fft_list = np.asarray(fft_df['fft'].tolist())\n",
    "    for num_ in [3,6,10,100]:\n",
    "        fft_list_m10=np.copy(fft_list); fft_list_m10[num_:-num_]=0\n",
    "        if num_ == 3:\n",
    "            fft_3_high.append(list(np.fft.ifft(fft_list_m10).real.tolist()))\n",
    "        if num_ == 6:\n",
    "            fft_6_high.append(list(np.fft.ifft(fft_list_m10).real.tolist()))\n",
    "        if num_ == 10:\n",
    "            fft_10_high.append(list(np.fft.ifft(fft_list_m10).real.tolist()))\n",
    "        fft_list_m10=np.copy(fft_list); fft_list_m10[num_:-num_]=0\n",
    "        if num_ == 100:\n",
    "            fft_100_high.append(list(np.fft.ifft(fft_list_m10).real.tolist()))\n",
    "    return(fft_df)\n",
    "\n",
    "\n",
    "#Create a function to process the data into 7 day look back slices\n",
    "def processData(data,lb):\n",
    "    X,Y = [],[]\n",
    "    for i in range(len(data)-lb-1):\n",
    "        X.append(data[i:(i+lb),0])\n",
    "        Y.append(data[(i+lb),0])\n",
    "    return np.array(X),np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_name = 'AI'  #AF   AIR   AI\n",
    "stock = stock_name+'.csv'\n",
    "\n",
    "fft_3_high = []\n",
    "fft_6_high = []\n",
    "fft_10_high = []\n",
    "fft_100_high = []\n",
    "\n",
    "fft_3_low = []\n",
    "fft_6_low = []\n",
    "fft_10_low = []\n",
    "fft_100_low = []\n",
    "\n",
    "fft_3_close = []\n",
    "fft_6_close = []\n",
    "fft_10_close = []\n",
    "fft_100_close = []\n",
    "\n",
    "df = format_dataset(stock)\n",
    "df_fft_close = fourier_transform_close(df,fft_3_close,fft_6_close,fft_10_close,fft_100_close)\n",
    "df_fft_low = fourier_transform_low(df,fft_3_low,fft_6_low,fft_10_low, fft_100_low)\n",
    "df_fft_high = fourier_transform_high(df,fft_3_high,fft_6_high,fft_10_high, fft_100_high)\n",
    "\n",
    "fft_3_close = list(itertools.chain.from_iterable(fft_3_close))\n",
    "fft_6_close = list(itertools.chain.from_iterable(fft_6_close))\n",
    "fft_10_close = list(itertools.chain.from_iterable(fft_10_close))\n",
    "fft_100_close = list(itertools.chain.from_iterable(fft_100_close))\n",
    "\n",
    "fft_3_high = list(itertools.chain.from_iterable(fft_3_high))\n",
    "fft_6_high = list(itertools.chain.from_iterable(fft_6_high))\n",
    "fft_10_high = list(itertools.chain.from_iterable(fft_10_high))\n",
    "fft_100_high = list(itertools.chain.from_iterable(fft_100_high))\n",
    "\n",
    "fft_3_low = list(itertools.chain.from_iterable(fft_3_low))\n",
    "fft_6_low = list(itertools.chain.from_iterable(fft_6_low))\n",
    "fft_10_low = list(itertools.chain.from_iterable(fft_10_low))\n",
    "fft_100_low = list(itertools.chain.from_iterable(fft_100_low))\n",
    "\n",
    "\n",
    "\n",
    "df_dict = {'index': list(range(0,len(df))),'name':df.name.values.tolist(), 'date':df.date.values.tolist(), 'volume':df.volume.values.tolist(), 'fft_3_close':fft_3_close,'fft_6_close':fft_6_close,'fft_10_close':fft_10_close, 'fft_100_close':fft_100_close, 'fft_3_high':fft_3_high,'fft_6_high':fft_6_high,'fft_10_high':fft_10_high,'fft_100_high':fft_100_high,'fft_3_low':fft_3_low , 'fft_6_low':fft_6_low,'fft_10_low':fft_10_low, 'fft_100_low':fft_100_low}\n",
    "df = pd.DataFrame(df_dict) \n",
    "df = get_technical_indicators(df)\n",
    "df2 = get_technical_indicators(df)\n",
    "df = df[['date', 'fft_3_close','fft_6_close','fft_10_close','fft_100_close', 'fft_3_low','fft_6_low','fft_10_low', 'fft_100_low', 'fft_3_high','fft_6_high','fft_10_high','fft_100_high', 'volume', 'var_mma', 'var_macd','var_bollinger', 'ema','upper_band', 'lower_band']]\n",
    "pct_close_mvt = get_movement(df)\n",
    "fft = df.fft_100_close.values.tolist()\n",
    "\n",
    "i = 0\n",
    "momentum = []\n",
    "while i < len(fft):\n",
    "    momentum.append(fft[i]-fft[i-1])\n",
    "    i += 1\n",
    "i = 0\n",
    "while i < len(momentum):\n",
    "    if momentum[i] > 0:\n",
    "        momentum[i] = 1\n",
    "    else:\n",
    "        momentum[i] = 0\n",
    "    i += 1\n",
    "\n",
    "i = 0\n",
    "fft = df.fft_100_close.values.tolist()\n",
    "var_bollinger = df.var_bollinger.values.tolist()\n",
    "\n",
    "variation = []\n",
    "i = 1\n",
    "while i < len(var_bollinger):\n",
    "    variation.append(var_bollinger[i]-var_bollinger[i-1])\n",
    "    i += 1\n",
    "\n",
    "upper = df.upper_band.values.tolist()\n",
    "lower = df.lower_band.values.tolist()\n",
    "stock_bollinger_upper = []\n",
    "stock_bollinger_lower = []\n",
    "value_bollinger = []\n",
    "i = 0\n",
    "while i < len(fft):\n",
    "    stock_bollinger_upper.append(fft[i]-upper[i])\n",
    "    stock_bollinger_lower.append(fft[i]-lower[i])\n",
    "    i += 1\n",
    "    \n",
    "print(len(stock_bollinger_lower))\n",
    "i = 0\n",
    "while i < len(fft):\n",
    "    if str(stock_bollinger_upper[i]) == 'nan':\n",
    "        value_bollinger.append(100)\n",
    "    elif stock_bollinger_upper[i] > 0:\n",
    "        value_bollinger.append(1)\n",
    "    elif stock_bollinger_lower[i] < 0:\n",
    "        value_bollinger.append(-1)\n",
    "    elif stock_bollinger_upper[i] < 0 and  stock_bollinger_lower[i] > 0:\n",
    "        value_bollinger.append(0)\n",
    "    i += 1\n",
    "print(len(value_bollinger))\n",
    "value_macd = []\n",
    "var_macd_list = df.var_macd.values.tolist()\n",
    "i = 0\n",
    "while i < len(var_macd_list):\n",
    "    if var_macd_list[i] > 0:\n",
    "        value_macd.append(1)\n",
    "    elif var_macd_list[i] < 1:\n",
    "        value_macd.append(-1)\n",
    "    else:\n",
    "        value_macd.append(0)\n",
    "    i += 1\n",
    "\n",
    "value_mma = []\n",
    "var_mma_list = df.var_mma.values.tolist()\n",
    "i = 0\n",
    "while i < len(var_mma_list):\n",
    "    if var_mma_list[i] > 0:\n",
    "        value_mma.append(1)\n",
    "    elif var_mma_list[i] < 1:\n",
    "        value_mma.append(-1)\n",
    "    else:\n",
    "        value_mma.append(0)\n",
    "    i += 1\n",
    "\n",
    "df_dict = {'date':df.date.values.tolist(),'pct_close_mvt':pct_close_mvt,'fft_3_close':df.fft_3_close.values.tolist(),'fft_6_close':df.fft_6_close.values.tolist(),'fft_10_close':df.fft_10_close.values.tolist(),'fft_3_low':df.fft_3_low.values.tolist(),'fft_6_low':df.fft_6_low.values.tolist(),'fft_10_low':df.fft_10_low.values.tolist(),'fft_3_high':df.fft_3_high.values.tolist(),'fft_6_high': df.fft_6_high.values.tolist(),'fft_10_high':df.fft_10_high.values.tolist(),'fft_100_close': df.fft_100_close.values.tolist(),'fft_100_low': df.fft_100_low.values.tolist(),'fft_100_high': df.fft_100_high.values.tolist(),'value_bollinger':value_bollinger,'value_macd':value_macd, 'value_mma':value_mma,'var_bollinger':df.var_bollinger.values.tolist(), 'momentum':momentum}\n",
    "df = pd.DataFrame(df_dict) \n",
    "\n",
    "momentum = df.momentum.values.tolist()\n",
    "print(len(momentum))\n",
    "label = []\n",
    "i = 0\n",
    "while i < len(momentum)-1:\n",
    "    if momentum[i] == 0 and momentum[i+1] == 0:\n",
    "        label.append(0)\n",
    "    elif momentum[i] == 1 and momentum[i+1] == 1:\n",
    "        label.append(0)\n",
    "    elif momentum[i] == 1 and momentum[i+1] == 0:\n",
    "        label.append(1)\n",
    "    elif momentum[i] == 0 and momentum[i+1] == 1:\n",
    "        label.append(2)\n",
    "    i += 1\n",
    "        \n",
    "if momentum[241] == 0 and momentum[242] == 0:\n",
    "    label.append(0)\n",
    "elif momentum[241] == 1 and momentum[242] == 1:\n",
    "    label.append(0)\n",
    "elif momentum[241] == 0 and momentum[242] == 1:\n",
    "    label.append(1)\n",
    "elif momentum[241] == 1 and momentum[242] == 0:\n",
    "    label.append(2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(df2.date.values.tolist(),df2.fft_100_close.values.tolist(), label='fft100_close')\n",
    "plt.plot(df2.date.values.tolist(),df2.amd20.values.tolist(), label='ema20')\n",
    "plt.plot(df2.date.values.tolist(),df2.amd50.values.tolist(), label='ema50')\n",
    "plt.plot(df2.date.values.tolist(),df2.upper_band.values.tolist(), label='upper')\n",
    "plt.plot(df2.date.values.tolist(),df2.lower_band.values.tolist(), label='lower')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "#plt.plot(df2.date.values.tolist(),df2.fft_100_close.values.tolist(), label='fft100_close')\n",
    "plt.plot(df2.date.values.tolist(),df2.MACD.values.tolist(), label='MACD')\n",
    "plt.plot(df2.date.values.tolist(),df2.signal.values.tolist(), label='signal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(df2.date.values.tolist(),df2.fft_100_low.values.tolist(), label='fft100_low')\n",
    "plt.plot(df2.date.values.tolist(),df2.fft_10_low.values.tolist(), label='fft_10_low')\n",
    "plt.plot(df2.date.values.tolist(),df2.fft_6_low.values.tolist(), label='fft_6_low')\n",
    "plt.plot(df2.date.values.tolist(),df2.fft_3_low.values.tolist(), label='fft_3_low')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(df2.date.values.tolist(),df2.fft_100_high.values.tolist(), label='fft100_high')\n",
    "plt.plot(df2.date.values.tolist(),df2.fft_10_high.values.tolist(), label='fft_10_high')\n",
    "plt.plot(df2.date.values.tolist(),df2.fft_6_high.values.tolist(), label='fft_6_high')\n",
    "plt.plot(df2.date.values.tolist(),df2.fft_3_high.values.tolist(), label='fft_3_high')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(df2.date.values.tolist(),df2.fft_100_close.values.tolist(), label='fft100_close')\n",
    "plt.plot(df2.date.values.tolist(),df2.fft_100_high.values.tolist(), label='fft_100_high')\n",
    "plt.plot(df2.date.values.tolist(),df2.fft_100_low.values.tolist(), label='fft_100_low')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 14\n",
    "epochs = 1000\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_prices_close = df.fft_100_close.values.astype('float32')\n",
    "stock_prices_low = df.fft_100_low.values.astype('float32')\n",
    "stock_prices_high = df.fft_100_high.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_prices_close = stock_prices_close.reshape(len(stock_prices_close), 1)\n",
    "stock_prices_low = stock_prices_low.reshape(len(stock_prices_low), 1)\n",
    "stock_prices_high = stock_prices_high.reshape(len(stock_prices_high), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "stock_prices_close = scaler.fit_transform(stock_prices_close)\n",
    "stock_prices_low = scaler.fit_transform(stock_prices_low)\n",
    "stock_prices_high = scaler.fit_transform(stock_prices_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training set and test set\n",
    "train_size = int(len(stock_prices_close) * 0.67)\n",
    "test_size = len(stock_prices_close) - train_size\n",
    "train, test = stock_prices_close[0:train_size,:], stock_prices_close[train_size:len(stock_prices_close),:]\n",
    "\n",
    "print('Split data into training set and test set... Number of training samples/ test samples:', len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# convert Apple's stock price data into time series dataset\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "# reshape input of the LSTM to be format [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(look_back, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(trainX, trainY, nb_epoch=epochs, batch_size=batch_size)\n",
    "\n",
    "\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "\n",
    "# shift predictions of training data for plotting\n",
    "trainPredictPlot = np.empty_like(stock_prices_close)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "\n",
    "# shift predictions of test data for plotting\n",
    "testPredictPlot = np.empty_like(stock_prices_close)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(stock_prices_close)-1, :] = testPredict\n",
    "\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(stock_prices_close))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training set and test set\n",
    "train_size = int(len(stock_prices_low) * 0.67)\n",
    "test_size = len(stock_prices_low) - train_size\n",
    "train, test = stock_prices_low[0:train_size,:], stock_prices_low[train_size:len(stock_prices_low),:]\n",
    "\n",
    "print('Split data into training set and test set... Number of training samples/ test samples:', len(train), len(test))\n",
    "\n",
    "def create_dataset(dataset, look_back):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# convert Apple's stock price data into time series dataset\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "# reshape input of the LSTM to be format [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(look_back, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(trainX, trainY, nb_epoch=epochs, batch_size=batch_size)\n",
    "\n",
    "\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "\n",
    "# shift predictions of training data for plotting\n",
    "trainPredictPlot = np.empty_like(stock_prices_low)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "\n",
    "# shift predictions of test data for plotting\n",
    "testPredictPlot = np.empty_like(stock_prices_low)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(stock_prices_low)-1, :] = testPredict\n",
    "\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(stock_prices_low))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training set and test set\n",
    "train_size = int(len(stock_prices_high) * 0.67)\n",
    "test_size = len(stock_prices_high) - train_size\n",
    "train, test = stock_prices_high[0:train_size,:], stock_prices_high[train_size:len(stock_prices_high),:]\n",
    "\n",
    "print('Split data into training set and test set... Number of training samples/ test samples:', len(train), len(test))\n",
    "\n",
    "def create_dataset(dataset, look_back):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# convert Apple's stock price data into time series dataset\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "# reshape input of the LSTM to be format [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(look_back, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(trainX, trainY, nb_epoch=epochs, batch_size=batch_size)\n",
    "\n",
    "\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "\n",
    "# shift predictions of training data for plotting\n",
    "trainPredictPlot = np.empty_like(stock_prices_high)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "\n",
    "# shift predictions of test data for plotting\n",
    "testPredictPlot = np.empty_like(stock_prices_high)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(stock_prices_high)-1, :] = testPredict\n",
    "\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(stock_prices_high))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_test = pd.DataFrame(data = np.arange(0,100))\n",
    "df_test_ewma = df_test.ewma(span=2).mean()\n",
    "df['26ema'] = pd.ewma(df['fft_100_close'], span=26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
